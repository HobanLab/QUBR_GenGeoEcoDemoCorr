View(tmp)
#figuring out how many individuals weren't in the new data that were in the old data....
inds_not_found_in_2025 <- fixed_field_data_processed %>%
filter(Metal_ID %notin% cleaned_data_adults$Metal_ID) %>%
filter(Metal_ID %notin% LC_weird_data_adults_cleaned$Metal_ID) %>%
select(Metal_ID, QUBR_ID, lat, long)
inds_w_typos <- cleaned_data_adults %>%
group_by(Metal_ID) %>%
filter(n() > 1) %>%
filter(!is.na(Metal_ID))
View(inds_w_typos)
?arrange
inds_w_typos <- cleaned_data_adults %>%
group_by(Metal_ID) %>%
filter(n() > 1) %>%
filter(!is.na(Metal_ID)) %>%
arrange(Metal_ID)
View(inds_w_typos)
?geodist
??geodist
####Quick and dirty comparison of the trees that we sampled twice in 2025####
library(geodist)
install.packages("geodist")
####Quick and dirty comparison of the trees that we sampled twice in 2025####
library(geodist)
?geodist
inds_w_typos_latlong <- inds_w_typos %>%
select(Lat, Long)
View(inds_w_typos_latlong)
#BT 175
geodist(inds_w_typos[1:2], paired = T)
inds_w_typos_latlong <- inds_w_typos %>%
select(Long, Lat)
#BT 175
geodist(inds_w_typos[1:2], paired = T)
inds_w_typos_latlong <- inds_w_typos %>%
select(Long, Lat) %>%
rename(longitude = Long,
latitude = Lat)
#BT 175
geodist(inds_w_typos[1:2], paired = T)
inds_w_typos_latlong <- inds_w_typos %>%
ungroup() %>%
select(Long, Lat) %>%
rename(longitude = Long,
latitude = Lat)
#BT 175
geodist(inds_w_typos[1:2], paired = T)
#BT 175
geodist(inds_w_typos_latlong[1:2], paired = T)
inds_w_typos_latlong[1:2]
inds_w_typos_latlong[,1:2]
inds_w_typos_latlong[1:2,]
#BT 175
geodist(inds_w_typos_latlong[1:2,], paired = T)
#BT 175
geodist(inds_w_typos_latlong[1:2,])
geodist(inds_w_typos_latlong[1:2,])
#BT 175
geodist(inds_w_typos_latlong[1:2,], paired = T)
#BT 175
geodist(inds_w_typos_latlong[1:2,], sequential = T)
inds_w_typos_latlong <- inds_w_typos %>%
select(Long, Lat) %>%
rename(longitude = Long,
latitude = Lat)
View(inds_w_typos)
#BT 175
geodist(inds_w_typos_latlong[1:2,], sequential = T)
#BT 177
geodist(inds_w_typos_latlong[3:4,], sequential = T)
#BT 178
geodist(inds_w_typos_latlong[5:6,], sequential = T)
#BT 181
geodist(inds_w_typos_latlong[7:8,], sequential = T)
inds_w_typos[2,]$horiz_accuracy_m
inds_w_typos[1,]$horiz_accuracy_m
#BT 175
geodist(inds_w_typos_latlong[1:2,], sequential = T)
inds_w_typos[1,]$fixtype
inds_w_typos[2,]$fixtype
View(inds_w_typos)
#BT 177
geodist(inds_w_typos_latlong[3:4,], sequential = T)
#BT 178
geodist(inds_w_typos_latlong[5:6,], sequential = T)
#BT 181
geodist(inds_w_typos_latlong[7:8,], sequential = T)
inds_w_typos$height[7]
#BT 177
abs(inds_w_typos$height[3] -inds_w_typos$height[4])
#BT 178
abs(inds_w_typos$height[5] -inds_w_typos$height[6])
#BT 181
abs(inds_w_typos$height[7] -inds_w_typos$height[8])
inds_w_typos <- cleaned_data_adults %>%
col_number() %>%
group_by(Metal_ID) %>%
filter(n() > 1) %>%
filter(!is.na(Metal_ID)) %>%
arrange(Metal_ID)
inds_w_typos <- cleaned_data_adults %>%
mutate(colnum = col_number()) %>%
group_by(Metal_ID) %>%
filter(n() > 1) %>%
filter(!is.na(Metal_ID)) %>%
arrange(Metal_ID)
inds_w_typos <- cleaned_data_adults %>%
mutate(rownum = row_number()) %>%
group_by(Metal_ID) %>%
filter(n() > 1) %>%
filter(!is.na(Metal_ID)) %>%
arrange(Metal_ID)
View(cleaned_data_adults)
#Getting rid of the worse resolution duplicates
cleaned_data_adults_final <- cleaned_data_adults %>%
mutate(rownum = row_number()) %>%
filter(rownum %notin% filter(inds_w_typos, fixtype != "RTK"))
#Getting rid of the worse resolution duplicates
cleaned_data_adults_final <- cleaned_data_adults %>%
mutate(rownum = row_number()) %>%
filter(rownum %notin% filter(inds_w_typos, fixtype != "RTK")$rownum)
filter(inds_w_typos, fixtype != "RTK")
####Merging with Rebecca####
#read in data that was generated via "combining_daniel_and_ash_pt_data.R"
old_data <- read_csv("/Users/Ashley/Desktop/Hoban/Quercus_brandegeei/exploring_data/processing_2023_adult_data/fixed_field_data_processed.csv") %>%
select(!c(Stick, Tree_pic, Env_pic, Recorder, Date, Page, Transcriber, Checked.)) %>%
mutate(Metal_ID = as.character(Metal_ID))
cleaned_data_adults_for_rebecca <- cleaned_data_adults_final %>%
full_join(., old_data, by =join_by(Metal_ID))
####Checking the merged data for errors/mismatches####
#checking to see if there are any mismatched QUBR ID's between datasets
tmp <- cleaned_data_adults_for_rebecca %>%
filter(!is.na(QUBR_ID.x)) %>%
filter(QUBR_ID.x != QUBR_ID.y) %>%
select(QUBR_ID.x, QUBR_ID.y, Metal_ID)
#checking to see if there are any mismatched site IDs between datasets
tmp <- cleaned_data_adults_for_rebecca %>%
filter(locality != Locality) %>%
select(Metal_ID, locality, Locality)
#checking to see if we have any individuals which have DBH's measured in both datasets to see if we are getting similar dbh measures
tmp <- filter(cleaned_data_adults_for_rebecca, !is.na(DBH_ag.x) & !is.na(DBH_ag.y)) %>%
select(Metal_ID, DBH_ag.x, DBH_ag.y)
#checking to see if there are any other individuals which I accidentally entered height in DBH category
tmp <- filter(cleaned_data, is.na(height) & !is.na(DBH1)) %>%
select(Metal_ID, QUBR_ID, height, DBH1, DBH2, notes)
#I want am overwriting old DBHs, multistemmed, locality, lat/long BUT I don't want to overwrite old QUBR_ID's --> if we have 2 I want to maintain the older one (which is the right dataset in the merge so the .y cols with identical names)
cleaned_data_for_rebecca <- cleaned_data_adults_for_rebecca %>%
mutate(QUBR_ID = case_when(is.na(QUBR_ID.x) ~ QUBR_ID.y,
!is.na(QUBR_ID.x) & !is.na(QUBR_ID.y) ~ QUBR_ID.y,
.default = QUBR_ID.x),
DBH_ag = case_when(is.na(DBH_ag.x) ~ DBH_ag.y,
.default = DBH_ag.x),
multistemmed = case_when(is.na(multistemmed.x) ~ multistemmed.y,
.default = multistemmed.x),
locality = case_when(is.na(Locality) ~ locality,
.default = Locality),
lat = case_when(is.na(Lat) ~ lat,
.default = Lat),
long = case_when(is.na(Long) ~ long,
.default = Long)) %>%
rename(notes_new_data = notes,
notes_old_data = Comments) %>%
select(c(Metal_ID, QUBR_ID, locality, lat, long, altitude, fruiting, DBH_ag, multistemmed, height, Canopy_short, Canopy_long,  notes_new_data, notes_old_data, horiz_accuracy_m, vert_accuracy_m, Crown_spread, eccentricity, Canopy_area, positionsourcetype, fixtype, numsats))
#checking for inds with no QUBR_ID --> this should be essentially no trees but instead there were 10 --> hand checked these to figure out + assign their ID's
tmp <- filter(cleaned_data_for_rebecca, is.na(QUBR_ID)) %>%
select(Metal_ID, QUBR_ID, DBH_ag, height, notes_new_data, notes_old_data)
####Load in the bad data from LC####
LC_weird_data <- read_csv("/Users/Ashley/Desktop/Hoban/Quercus_brandegeei/field_work/2025_Nov/Nov_2025_GPS_data/mother_pts.csv") %>%
select(!c(lat, long_))
LC_mom_branches <- filter(LC_weird_data, str_detect(notes, "Branch"))
LC_weird_data_adults_cleaned <- LC_weird_data %>%
filter(str_detect(notes, "ranch", negate = T)) %>%
select(!c(mother_tree_num, num_branches)) %>%
separate_wider_delim(notes, ", ", names = c("height", "fruiting", "leaves_coll", "DBH1", "notes"), too_few = "align_start", too_many = "merge") %>% # the notes column contains info split by commas that I am spliting into up to 5 unique columns
mutate(fruiting = case_when(is.na(qubr_id) & leaves_coll == "Y" ~ "Y",
.default = fruiting),
leaves_coll = case_when(is.na(qubr_id) & leaves_coll == "Y" ~ "N",
.default = leaves_coll)) %>% # cleaning up errored inputs where I accidentally put a N for fruiting and Y for leaves collected but didn't note a QUBR_ID (so almost certainly didn't actually collect leaves)
rename(Metal_ID = metal_id,
QUBR_ID = qubr_id) %>%
mutate(DBH2 = str_extract(notes, "(?<=DBH\\s?2: )\\d*\\.?\\d"),
DBH3 = str_extract(notes, "(?<=DBH\\s?3: )\\d*\\.?\\d"),
Metal_ID_new = str_extract(notes, "(?<=ew BT: )\\d*")) %>% # pulling out DBH2 and 3 and new metal tag ID's from the notes info
mutate(across(starts_with("DBH"), ~ (as.numeric(.x)/100)^2)) %>% # squaring all of the DBH's and then summing them and then sqrting the sum is how people in the US tend to use multi-stem dbh's
mutate(DBH_ag = sqrt(rowSums(across(starts_with("DBH")), na.rm = T))) %>%
mutate(multistemmed = case_when(is.na(DBH2) ~ F,
!is.na(DBH2) ~ T),
DBH_ag = case_when(DBH_ag != 0 ~ DBH_ag,
.default = NA)) %>% # adding a column that is a logical vector that describes if the tree has multiple stems or not
select(!c(DBH1, DBH2, DBH3)) %>%
mutate(Metal_ID = as.character(Metal_ID),
height = as.numeric(height),
Locality = "LC") # add locality info since all data from this layer is from LC
#check if we have any of the same trees in the weird LC data and the better data from 2025
tmp <- LC_weird_data_adults_cleaned %>%
filter(Metal_ID %in%  cleaned_data_adults$Metal_ID)
####Joining previously joined data with the weird LC data####
all_cleaned_data_for_rebecca <- LC_weird_data_adults_cleaned  %>%
full_join(., cleaned_data_for_rebecca, by =join_by(Metal_ID)) %>%
mutate(QUBR_ID = case_when(is.na(QUBR_ID.x) ~ QUBR_ID.y,
.default = QUBR_ID.x),
DBH_ag = case_when(is.na(DBH_ag.x) ~ DBH_ag.y,
.default = DBH_ag.x),
multistemmed = case_when(is.na(multistemmed.x) ~ multistemmed.y,
.default = multistemmed.x),
fruiting = case_when(is.na(fruiting.x) ~ fruiting.y,
.default = fruiting.x),
height = case_when(is.na(height.x) ~ height.y,
.default = height.x),
locality = case_when(is.na(Locality) ~ locality,
.default = Locality),
lat = case_when(is.na(Lat) ~ lat,
.default = Lat),
long = case_when(is.na(Long) ~ long,
.default = Long),
notes_new_data = case_when(is.na(notes) ~ notes_new_data,
.default = notes_new_data)) %>% #creating new columns with data from the LC weirdos where it's present and with the previously merged data where it's not
mutate(fruiting = case_when(str_detect(notes_new_data, "acorn") ~ "Y",
.default = fruiting)) %>% # Making sure that if the notes mention acorns, the fruiting column has a yes bc I noticed a few columns that said no to fruiting but had notes about acorns
select(c(Metal_ID, QUBR_ID, locality, lat, long, altitude, fruiting, DBH_ag, multistemmed, height, Canopy_short, Canopy_long,  notes_new_data, notes_old_data, horiz_accuracy_m, vert_accuracy_m, Crown_spread, eccentricity, Canopy_area, positionsourcetype, fixtype, numsats)) #keeping only the necessary columns
#figuring out how many new individuals we sampled in 2025 (that we didn't in 2023)
tmp <- all_cleaned_data_for_rebecca %>%
filter(QUBR_ID %notin% fixed_field_data_processed$QUBR_ID)
####Some quick visualization####
#plotting heights to see if anything looks crazy
cleaned_data_adults %>%
ggplot() +
geom_violin(aes(y = height, x = locality, fill = locality)) +
geom_boxplot(aes(y = height, x = locality), width= .1, outliers = F)
write.csv(inds_not_found_in_2025, "/Users/Ashley/Desktop/Hoban/Quercus_brandegeei/exploring_data/Nov_2025_GPS_data/final_cleaned_data_for_Rebecca.csv")
write.csv(all_cleaned_data_for_rebecca, "/Users/Ashley/Desktop/Hoban/Quercus_brandegeei/exploring_data/Nov_2025_GPS_data/final_cleaned_data_for_Rebecca.csv")
setwd("/Users/Ashley/Desktop/Hoban/Quercus_brandegeei/exploring_data/Nov_2025_GPS_data")
raw_data <- read_csv("/Users/Ashley/Desktop/Hoban/Quercus_brandegeei/field_work/2025_Nov/Nov_2025_GPS_data/Revised_QUBR_locations.csv")
# Create a function that is the opposite of %in%
`%notin%` <- Negate(`%in%`)
####Cleaning + formatting the new data in prep for merging####
cleaned_data <- raw_data %>%
filter(notes != "Practice" | is.na(notes)) %>%
rename_with(~str_remove(., "esrignss_")) %>%
rename(horiz_accuracy_m = h_rms,
vert_accuracy_m = v_rms) %>%
mutate(positionsourcetype = case_when(positionsourcetype == 1 ~ "user",
positionsourcetype == 3 ~ "GPS"),
fixtype = case_when(fixtype == 1 ~ "GPS",
fixtype == 2 ~ "DGPS",
fixtype == 4 ~ "RTK")) %>%
dplyr::select(bt_id, dbh_1, notes, height, leaves_coll, locality, date_coll, qubr_id_2, fruiting, Lat, Long, altitude,  horiz_accuracy_m, vert_accuracy_m, positionsourcetype, fixtype, correctionage, numsats) %>%
rename(Metal_ID = bt_id,
QUBR_ID = qubr_id_2,
Date = date_coll,
DBH1 = dbh_1) %>%
mutate(DBH2 = str_extract(notes, "(?<=DBH\\s?2: )\\d*\\.?\\d"),
DBH3 = str_extract(notes, "(?<=DBH\\s?3: )\\d*\\.?\\d"),
Metal_ID_new = str_extract(notes, "(?<=ew BT: )\\d*"),
Metal_ID = str_remove(Metal_ID, "^0"),
row = row_number())
cleaned_data_for_AJ <- cleaned_data %>%
filter(str_detect(notes, "AJ") | str_detect(Metal_ID, "AJ"))
cleaned_data_mom_branches <- cleaned_data %>%
filter(str_detect(notes, "Branch"))
cleaned_data_tmp <- cleaned_data %>%
filter(row %notin% cleaned_data_for_AJ$row) %>%
filter(row %notin% cleaned_data_mom_branches$row) %>%
mutate(QUBR_ID = case_when(str_detect(QUBR_ID, "-") ~ str_replace(QUBR_ID, "-", "_"),
.default = QUBR_ID)) %>%
mutate(QUBR_ID = case_when(str_detect(notes, "_") ~ str_extract(notes, "[A-Z]*_[0-9]*"),
.default = QUBR_ID)) %>%
dplyr::select(!row)
cleaned_data_count_trunks_unsampled <- cleaned_data_for_AJ%>%
dplyr::select(!row) %>%
rbind(
filter(cleaned_data_tmp, str_detect(notes, "stem|trunk|more|too"))) %>%
filter(Metal_ID %notin% c('For AJ: no', 'For AJ: No'))
cleaned_data_adults <- cleaned_data_tmp %>%
mutate(across(starts_with("DBH"), ~ (as.numeric(.x)/100)^2)) %>% #Squaring all of the DBH's and then summing them and then sqrting the sum is how people in the US tend to use multi-stem dbh's
mutate(DBH_ag = sqrt(rowSums(across(starts_with("DBH")), na.rm = T))) %>%
mutate(multistemmed = case_when(is.na(DBH2) ~ F,
!is.na(DBH2) ~ T),
DBH_ag = case_when(DBH_ag != 0 ~ DBH_ag,
.default = NA)) %>% # adding a column that is a logical vector that describes if the tree has multiple stems or not
select(!c(DBH1, DBH2, DBH3))
####Checking for individuals which we collected data for twice in 2025####
inds_w_typos <- cleaned_data_adults %>%
mutate(rownum = row_number()) %>%
group_by(Metal_ID) %>%
filter(n() > 1) %>%
filter(!is.na(Metal_ID)) %>%
arrange(Metal_ID)
#Quick and dirty comparison of the trees that we sampled twice in 2025
library(geodist)
inds_w_typos_latlong <- inds_w_typos %>%
select(Long, Lat) %>%
rename(longitude = Long,
latitude = Lat)
#BT 175
geodist(inds_w_typos_latlong[1:2,], sequential = T) #fairly large distance --> uncertain as to why --> will want to take the point with more satelites probably
#BT 177
geodist(inds_w_typos_latlong[3:4,], sequential = T)
#BT 178
geodist(inds_w_typos_latlong[5:6,], sequential = T)
#BT 181
geodist(inds_w_typos_latlong[7:8,], sequential = T)
#BT 177
abs(inds_w_typos$height[3] -inds_w_typos$height[4])
#BT 178
abs(inds_w_typos$height[5] -inds_w_typos$height[6])
#BT 181
abs(inds_w_typos$height[7] -inds_w_typos$height[8])
#Getting rid of the worse resolution duplicates (those which have the fixtype that ISN'T RTK)
cleaned_data_adults_final <- cleaned_data_adults %>%
mutate(rownum = row_number()) %>%
filter(rownum %notin% filter(inds_w_typos, fixtype != "RTK")$rownum)
####Merging with Rebecca####
#read in data that was generated via "combining_daniel_and_ash_pt_data.R"
old_data <- read_csv("/Users/Ashley/Desktop/Hoban/Quercus_brandegeei/exploring_data/processing_2023_adult_data/fixed_field_data_processed.csv") %>%
select(!c(Stick, Tree_pic, Env_pic, Recorder, Date, Page, Transcriber, Checked.)) %>%
mutate(Metal_ID = as.character(Metal_ID))
cleaned_data_adults_for_rebecca <- cleaned_data_adults_final %>%
full_join(., old_data, by =join_by(Metal_ID))
####Checking the merged data for errors/mismatches####
#checking to see if there are any mismatched QUBR ID's between datasets
tmp <- cleaned_data_adults_for_rebecca %>%
filter(!is.na(QUBR_ID.x)) %>%
filter(QUBR_ID.x != QUBR_ID.y) %>%
select(QUBR_ID.x, QUBR_ID.y, Metal_ID)
#checking to see if there are any mismatched site IDs between datasets
tmp <- cleaned_data_adults_for_rebecca %>%
filter(locality != Locality) %>%
select(Metal_ID, locality, Locality)
#checking to see if we have any individuals which have DBH's measured in both datasets to see if we are getting similar dbh measures
tmp <- filter(cleaned_data_adults_for_rebecca, !is.na(DBH_ag.x) & !is.na(DBH_ag.y)) %>%
select(Metal_ID, DBH_ag.x, DBH_ag.y)
#checking to see if there are any other individuals which I accidentally entered height in DBH category
tmp <- filter(cleaned_data, is.na(height) & !is.na(DBH1)) %>%
select(Metal_ID, QUBR_ID, height, DBH1, DBH2, notes)
#plotting heights to see if anything looks crazy
cleaned_data_adults %>%
ggplot() +
geom_violin(aes(y = height, x = locality, fill = locality)) +
geom_boxplot(aes(y = height, x = locality), width= .1, outliers = F)
#just taking a peak at the smaller heights to make sure I don't see any egregious typos
tmp <- filter(cleaned_data_adults, height <5) %>%
select(Metal_ID, QUBR_ID, DBH_ag, height, notes)
#I want am overwriting old DBHs, multistemmed, locality, lat/long BUT I don't want to overwrite old QUBR_ID's --> if we have 2 I want to maintain the older one (which is the right dataset in the merge so the .y cols with identical names)
cleaned_data_for_rebecca <- cleaned_data_adults_for_rebecca %>%
mutate(QUBR_ID = case_when(is.na(QUBR_ID.x) ~ QUBR_ID.y,
!is.na(QUBR_ID.x) & !is.na(QUBR_ID.y) ~ QUBR_ID.y,
.default = QUBR_ID.x),
DBH_ag = case_when(is.na(DBH_ag.x) ~ DBH_ag.y,
.default = DBH_ag.x),
multistemmed = case_when(is.na(multistemmed.x) ~ multistemmed.y,
.default = multistemmed.x),
locality = case_when(is.na(Locality) ~ locality,
.default = Locality),
lat = case_when(is.na(Lat) ~ lat,
.default = Lat),
long = case_when(is.na(Long) ~ long,
.default = Long)) %>%
rename(notes_new_data = notes,
notes_old_data = Comments) %>%
select(c(Metal_ID, QUBR_ID, locality, lat, long, altitude, fruiting, DBH_ag, multistemmed, height, Canopy_short, Canopy_long,  notes_new_data, notes_old_data, horiz_accuracy_m, vert_accuracy_m, Crown_spread, eccentricity, Canopy_area, positionsourcetype, fixtype, numsats))
#checking for inds with no QUBR_ID --> this should be essentially no trees but instead there were 10 --> hand checked these to figure out + assign their ID's
tmp <- filter(cleaned_data_for_rebecca, is.na(QUBR_ID)) %>%
select(Metal_ID, QUBR_ID, DBH_ag, height, notes_new_data, notes_old_data)
####Load in the bad data from LC####
LC_weird_data <- read_csv("/Users/Ashley/Desktop/Hoban/Quercus_brandegeei/field_work/2025_Nov/Nov_2025_GPS_data/mother_pts.csv") %>%
select(!c(lat, long_))
LC_mom_branches <- filter(LC_weird_data, str_detect(notes, "Branch"))
LC_weird_data_adults_cleaned <- LC_weird_data %>%
filter(str_detect(notes, "ranch", negate = T)) %>%
select(!c(mother_tree_num, num_branches)) %>%
separate_wider_delim(notes, ", ", names = c("height", "fruiting", "leaves_coll", "DBH1", "notes"), too_few = "align_start", too_many = "merge") %>% # the notes column contains info split by commas that I am spliting into up to 5 unique columns
mutate(fruiting = case_when(is.na(qubr_id) & leaves_coll == "Y" ~ "Y",
.default = fruiting),
leaves_coll = case_when(is.na(qubr_id) & leaves_coll == "Y" ~ "N",
.default = leaves_coll)) %>% # cleaning up errored inputs where I accidentally put a N for fruiting and Y for leaves collected but didn't note a QUBR_ID (so almost certainly didn't actually collect leaves)
rename(Metal_ID = metal_id,
QUBR_ID = qubr_id) %>%
mutate(DBH2 = str_extract(notes, "(?<=DBH\\s?2: )\\d*\\.?\\d"),
DBH3 = str_extract(notes, "(?<=DBH\\s?3: )\\d*\\.?\\d"),
Metal_ID_new = str_extract(notes, "(?<=ew BT: )\\d*")) %>% # pulling out DBH2 and 3 and new metal tag ID's from the notes info
mutate(across(starts_with("DBH"), ~ (as.numeric(.x)/100)^2)) %>% # squaring all of the DBH's and then summing them and then sqrting the sum is how people in the US tend to use multi-stem dbh's
mutate(DBH_ag = sqrt(rowSums(across(starts_with("DBH")), na.rm = T))) %>%
mutate(multistemmed = case_when(is.na(DBH2) ~ F,
!is.na(DBH2) ~ T),
DBH_ag = case_when(DBH_ag != 0 ~ DBH_ag,
.default = NA)) %>% # adding a column that is a logical vector that describes if the tree has multiple stems or not
select(!c(DBH1, DBH2, DBH3)) %>%
mutate(Metal_ID = as.character(Metal_ID),
height = as.numeric(height),
Locality = "LC") # add locality info since all data from this layer is from LC
#check if we have any of the same trees in the weird LC data and the better data from 2025
tmp <- LC_weird_data_adults_cleaned %>%
filter(Metal_ID %in%  cleaned_data_adults$Metal_ID)
####Joining previously joined data with the weird LC data####
all_cleaned_data_for_rebecca <- LC_weird_data_adults_cleaned  %>%
full_join(., cleaned_data_for_rebecca, by =join_by(Metal_ID)) %>%
mutate(QUBR_ID = case_when(is.na(QUBR_ID.x) ~ QUBR_ID.y,
.default = QUBR_ID.x),
DBH_ag = case_when(is.na(DBH_ag.x) ~ DBH_ag.y,
.default = DBH_ag.x),
multistemmed = case_when(is.na(multistemmed.x) ~ multistemmed.y,
.default = multistemmed.x),
fruiting = case_when(is.na(fruiting.x) ~ fruiting.y,
.default = fruiting.x),
height = case_when(is.na(height.x) ~ height.y,
.default = height.x),
locality = case_when(is.na(Locality) ~ locality,
.default = Locality),
lat = case_when(is.na(Lat) ~ lat,
.default = Lat),
long = case_when(is.na(Long) ~ long,
.default = Long),
notes_new_data = case_when(is.na(notes) ~ notes_new_data,
.default = notes_new_data)) %>% #creating new columns with data from the LC weirdos where it's present and with the previously merged data where it's not
mutate(fruiting = case_when(str_detect(notes_new_data, "acorn") ~ "Y",
.default = fruiting)) %>% # Making sure that if the notes mention acorns, the fruiting column has a yes bc I noticed a few columns that said no to fruiting but had notes about acorns
select(c(Metal_ID, QUBR_ID, locality, lat, long, altitude, fruiting, DBH_ag, multistemmed, height, Canopy_short, Canopy_long,  notes_new_data, notes_old_data, horiz_accuracy_m, vert_accuracy_m, Crown_spread, eccentricity, Canopy_area, positionsourcetype, fixtype, numsats)) #keeping only the necessary columns
write.csv(all_cleaned_data_for_rebecca, "/Users/Ashley/Desktop/Hoban/Quercus_brandegeei/exploring_data/Nov_2025_GPS_data/final_cleaned_data_for_Rebecca.csv")
# Read in the raw data from the Field_datasheets_filled_before_KA_check_copy.csv
field_data_raw <- read.csv("./data/Field_datasheets_filled_before_KA_check_copy.csv", na.strings = c("NA", ""))
setwd("/Users/Ashley/Desktop/Hoban/Quercus_brandegeei/REU_2024/github_proj/QUBR_GenGeoEcoDemoCorr")
# Read in the raw data from the Field_datasheets_filled_before_KA_check_copy.csv
field_data_raw <- read.csv("./data/Field_datasheets_filled_before_KA_check_copy.csv", na.strings = c("NA", ""))
daniel_data_raw <- read.csv("./data/2021Data_populations_metal_labels.csv", na.strings = "") #read in the csv with Daniels pt data
###Adding Daniel's pts into Ash's data####
daniel_data_in_ash_data <- daniel_data_raw %>%
mutate(W = paste0("-", W)) %>%
rename(lat = N,
long = W,
DBH = DAP.Total..m.,
tree_num = Núm.,
Daniel_tag = Num..Metal.label,
region = Region,
locality = Localidad,
altitude = Altitud..msnm.,
fruited_2020 = Con.Bellota..2020.,
collected_2020 = Colecta..2020.,
height = Altura..m.,
DRC = D..Basal..m.,
Canopy1 = Cob.1..m.,
Canopy2 = Cob.2..m.,
notes = Observaciones) %>%
mutate(across(c(lat, long), ~ gsub('° ', ' ', ., fixed = T)),
across(c(lat, long), ~ gsub('. ', '.', ., , fixed = T)),
across(c(lat, long), ~ measurements::conv_unit(., from = 'deg_dec_min', to = 'dec_deg')),
across(c(lat, long), ~ as.numeric(.))) %>%
mutate(across(starts_with("DBH"), ~ (.x/pi*100))) %>% #converting their circumference measurements in m to DBH in cm
mutate(DBH1 = case_when(is.na(DBH1) ~ DBH,
!is.na(DBH1) ~ DBH1)) %>% #making it so all DBH's are in the DBH1 column
filter(Daniel_tag %in% field_data_raw$Daniel_tag) %>% #filter to only keep rows (based on the number on the silver tags placed by Daniel) which are in Ash's field data
select(Daniel_tag, DBH1, DBH2, DBH3, DBH4, Canopy1, Canopy2, lat, long)
#need to figure out best way to pull Daniel data into ash data.... thought about left_join but resulted in a shit ton of duplicated columns that I didn't need --> perhaps best to reduce both datasets down to the bare necessities, rbind and then left join that back onto the big ash df?
field_data_processing <- field_data_raw %>%
left_join(., daniel_data_in_ash_data, by = "Daniel_tag") %>%
mutate(DBH1.x = ifelse(!is.na(Daniel_tag), DBH1.y, DBH1.x),
DBH2.x = ifelse(!is.na(Daniel_tag), DBH2.y, DBH2.x),
DBH3.x = ifelse(!is.na(Daniel_tag), DBH3.y, DBH3.x),
DBH4.x = ifelse(!is.na(Daniel_tag), DBH4.y, DBH4.x),
Canopy1.x = ifelse(!is.na(Daniel_tag), Canopy1.y, Canopy1.x),
Canopy2.x = ifelse(!is.na(Daniel_tag), Canopy2.y, Canopy2.x)) %>%
rename(Daniel_lat = lat,
Daniel_long = long) %>%
select(!ends_with(".y")) %>% #get rid of duplicated cols from Daniel's data
rename_with( ~ str_remove(., ".x")) #get rid of the .x remaning from the original cols
field_data_processed <- field_data_processing %>%
mutate(Canopy1 = as.numeric(Canopy1),
Canopy2 = as.numeric(Canopy2)) %>%
mutate(across(starts_with("DBH"), ~ (.x/100)^2)) %>% #Squaring all of the DBH's and then summing them and then sqrting the sum is how people in the US tend to use multi-stem dbh's (which is what 167 of my trees are)
mutate(DBH_ag = sqrt(rowSums(across(starts_with("DBH")), na.rm = T))) %>%
mutate(multistemmed = case_when(is.na(DBH2) ~ F,
!is.na(DBH2) ~ T)) %>% # adding a column that is a logical vector that describes if the tree has multiple stems or not
select(!c(DBH1, DBH2, DBH3, DBH4, DBH5, DBH6)) %>%
#filter(DBH_ag != 0) %>% #remove individuals with no DBH measurements
mutate(Canopy_short = case_when(Canopy1 <= Canopy2 ~ Canopy1,
Canopy2 < Canopy1 ~ Canopy2,),
Canopy_long = case_when(Canopy1 >= Canopy2 ~ Canopy1,
Canopy2 > Canopy1 ~ Canopy2,),
Crown_spread = (Canopy_short + Canopy_long)/2,
a = Canopy_long/2,
b = Canopy_short/2,
c = sqrt(a^2 - b^2),
eccentricity = c/a,
Canopy_area = pi*a*b) %>% #eccentricity is a measure of how circular the canopy is, equations for this found here: https://www.andrews.edu/~rwright/Precalculus-RLW/Text/07-03.html#:~:text=Eccentricity%20is%20a%20measure%20of,ellipse%20is%20almost%20a%20line., crown spread is the avg of our two measures of canopy length
filter(QUBR_ID != "LM_156") %>% #I used to remove individuals with no canopy measurements so this *used to* REMOVE POINTS WHICH DANIEL MEASURED AND WE DID NOT REMEASURE (probs like 20 inds) which I didn't want and was why I made this script --> then it was removing trees that simply had canopy axes values either of 0/NA or with a character in them which I also didn't want --> after playing around, it was easiest to just remove this single QUBR_ID that has no lat/long
mutate(Locality = as.factor(Locality)) %>% # make sure Locality is a factor
mutate(W = paste0("-", W)) %>%
rename(lat = N,
long = W) #fixing lat long names + data
filter(field_data_processing, QUBR_ID %notin% field_data_processed$QUBR_ID) %>%
select(c(QUBR_ID, Canopy1, Canopy2, N, W, Daniel_lat, Daniel_long)) #checking what trees are dropped during the data manipulation that happens to create the processed dataset
# Fixing lat/long points to be in dec deg for mapping#
fix_deg_dec_min_lat <- field_data_processed %>%
filter(grepl(" ", lat)) %>%
mutate(lat = measurements::conv_unit(lat, from = 'deg_dec_min', to = 'dec_deg')) %>%
select(c(QUBR_ID, lat))
fix_deg_dec_min_long <- field_data_processed %>%
filter(grepl(" ", long)) %>%
mutate(long = measurements::conv_unit(long, from = 'deg_dec_min', to = 'dec_deg')) %>%
select(c(QUBR_ID, long))
fixed_field_data_processed <- field_data_processed %>%
left_join(fix_deg_dec_min_long, by=join_by(QUBR_ID)) %>%
left_join(fix_deg_dec_min_lat, by=join_by(QUBR_ID)) %>%
mutate(lat = case_when(is.na(lat.y) ~ lat.x,
!is.na(lat.y) ~ lat.y),
long = case_when(is.na(long.y) ~ long.x,
!is.na(long.y) ~ long.y)) %>%
mutate(lat = as.numeric(lat),
long = as.numeric(long)) %>%
select(!c(lat.y, lat.x, long.y, long.x))
fixed_field_data_sf <- st_as_sf(fixed_field_data_processed, coords = c("long", "lat"), crs= 4326) #making a easy to plot on a map dataset even though I won't use it in this script
